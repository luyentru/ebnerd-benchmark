{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "# \n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL, \n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL, \n",
    "    DEFAULT_USER_COL, \n",
    ")\n",
    "#\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column, \n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history, \n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "from ebrec.utils._polars import concat_str_columns\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ebnerd_from_path(path:Path, history_size:int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function \n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .join(df_history, on=DEFAULT_USER_COL, how=\"inner\")\n",
    "        .collect()\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate labels\n",
    "We sample a few just to get started. For testset we just make up a dummy column with 0 and 1 - this is not the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"../downloads/demo\")\n",
    "HISTORY_SIZE = 30\n",
    "N_SAMPLES = 100\n",
    "df_train = (\n",
    "    ebnerd_from_path(path.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .pipe(sampling_strategy_wu2019,npratio=4,shuffle=True,with_replacement=True,seed=123,)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "# =>\n",
    "df_validation = (\n",
    "    ebnerd_from_path(path.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .pipe(create_binary_labels_column)\n",
    "    .sample(n=N_SAMPLES)\n",
    ")\n",
    "# =>\n",
    "df_test = (\n",
    "    ebnerd_from_path(path.joinpath(\"test\"), history_size=HISTORY_SIZE)\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_INVIEW_ARTICLES_COL)\n",
    "        .list.eval(pl.element() * 0)\n",
    "        .list.tail(-1)\n",
    "        .list.eval(pl.element().extend_constant(1, n=1))\n",
    "        .alias(DEFAULT_LABELS_COL)\n",
    "    )\n",
    "    .sample(n=N_SAMPLES)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the difference between Training/Validation and Testset\n",
    "Note, the testset doesn't include labels, and we have remove some of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 19)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>impression_id</th><th>article_id</th><th>impression_time</th><th>read_time</th><th>scroll_percentage</th><th>device_type</th><th>article_ids_inview</th><th>article_ids_clicked</th><th>user_id</th><th>is_sso_user</th><th>gender</th><th>postcode</th><th>age</th><th>is_subscriber</th><th>session_id</th><th>next_read_time</th><th>next_scroll_percentage</th><th>article_id_fixed</th><th>labels</th></tr><tr><td>u32</td><td>i32</td><td>datetime[μs]</td><td>f32</td><td>f32</td><td>i8</td><td>list[i64]</td><td>list[i64]</td><td>u32</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>bool</td><td>u32</td><td>f32</td><td>f32</td><td>list[i32]</td><td>list[i8]</td></tr></thead><tbody><tr><td>181760259</td><td>null</td><td>2023-02-26 12:31:32</td><td>13.0</td><td>null</td><td>2</td><td>[9651272, 9649677, … 9647661]</td><td>[9649290]</td><td>1966060</td><td>false</td><td>null</td><td>null</td><td>null</td><td>false</td><td>166180</td><td>3.0</td><td>null</td><td>[9644792, 9646176, … 9646402]</td><td>[0, 0, … 0]</td></tr><tr><td>42169409</td><td>null</td><td>2023-02-28 19:32:08</td><td>33.0</td><td>null</td><td>2</td><td>[9654866, 9653210, … 9654861]</td><td>[9654866]</td><td>1399580</td><td>false</td><td>null</td><td>null</td><td>null</td><td>false</td><td>145769</td><td>2.0</td><td>48.0</td><td>[9635113, 9645517, … 9646947]</td><td>[1, 0, … 0]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 19)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ impressio ┆ article_i ┆ impressio ┆ read_time ┆ … ┆ next_read ┆ next_scro ┆ article_i ┆ labels   │\n",
       "│ n_id      ┆ d         ┆ n_time    ┆ ---       ┆   ┆ _time     ┆ ll_percen ┆ d_fixed   ┆ ---      │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ f32       ┆   ┆ ---       ┆ tage      ┆ ---       ┆ list[i8] │\n",
       "│ u32       ┆ i32       ┆ datetime[ ┆           ┆   ┆ f32       ┆ ---       ┆ list[i32] ┆          │\n",
       "│           ┆           ┆ μs]       ┆           ┆   ┆           ┆ f32       ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 181760259 ┆ null      ┆ 2023-02-2 ┆ 13.0      ┆ … ┆ 3.0       ┆ null      ┆ [9644792, ┆ [0, 0, … │\n",
       "│           ┆           ┆ 6         ┆           ┆   ┆           ┆           ┆ 9646176,  ┆ 0]       │\n",
       "│           ┆           ┆ 12:31:32  ┆           ┆   ┆           ┆           ┆ …         ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 9646402]  ┆          │\n",
       "│ 42169409  ┆ null      ┆ 2023-02-2 ┆ 33.0      ┆ … ┆ 2.0       ┆ 48.0      ┆ [9635113, ┆ [1, 0, … │\n",
       "│           ┆           ┆ 8         ┆           ┆   ┆           ┆           ┆ 9645517,  ┆ 0]       │\n",
       "│           ┆           ┆ 19:32:08  ┆           ┆   ┆           ┆           ┆ …         ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 9646947]  ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 15)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>impression_id</th><th>impression_time</th><th>read_time</th><th>scroll_percentage</th><th>device_type</th><th>article_ids_inview</th><th>user_id</th><th>is_sso_user</th><th>gender</th><th>postcode</th><th>age</th><th>is_subscriber</th><th>session_id</th><th>article_id_fixed</th><th>labels</th></tr><tr><td>u32</td><td>datetime[μs]</td><td>f32</td><td>f32</td><td>i8</td><td>list[i32]</td><td>u32</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td><td>bool</td><td>u32</td><td>list[i32]</td><td>list[i32]</td></tr></thead><tbody><tr><td>294542904</td><td>2023-03-13 10:57:42</td><td>12.0</td><td>null</td><td>1</td><td>[9672801, 9673153, … 9667877]</td><td>2389317</td><td>false</td><td>null</td><td>null</td><td>null</td><td>false</td><td>57364</td><td>[9663935, 9663605, … 9667329]</td><td>[0, 0, … 1]</td></tr><tr><td>320871504</td><td>2023-03-14 18:26:38</td><td>95.0</td><td>100.0</td><td>2</td><td>[9675349, 9675372, … 9675304]</td><td>2348586</td><td>false</td><td>null</td><td>null</td><td>null</td><td>false</td><td>35530</td><td>[9665934, 9667530, … 9667800]</td><td>[0, 0, … 1]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 15)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ impressio ┆ impressio ┆ read_time ┆ scroll_pe ┆ … ┆ is_subscr ┆ session_i ┆ article_i ┆ labels   │\n",
       "│ n_id      ┆ n_time    ┆ ---       ┆ rcentage  ┆   ┆ iber      ┆ d         ┆ d_fixed   ┆ ---      │\n",
       "│ ---       ┆ ---       ┆ f32       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ list[i32 │\n",
       "│ u32       ┆ datetime[ ┆           ┆ f32       ┆   ┆ bool      ┆ u32       ┆ list[i32] ┆ ]        │\n",
       "│           ┆ μs]       ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 294542904 ┆ 2023-03-1 ┆ 12.0      ┆ null      ┆ … ┆ false     ┆ 57364     ┆ [9663935, ┆ [0, 0, … │\n",
       "│           ┆ 3         ┆           ┆           ┆   ┆           ┆           ┆ 9663605,  ┆ 1]       │\n",
       "│           ┆ 10:57:42  ┆           ┆           ┆   ┆           ┆           ┆ …         ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 9667329]  ┆          │\n",
       "│ 320871504 ┆ 2023-03-1 ┆ 95.0      ┆ 100.0     ┆ … ┆ false     ┆ 35530     ┆ [9665934, ┆ [0, 0, … │\n",
       "│           ┆ 4         ┆           ┆           ┆   ┆           ┆           ┆ 9667530,  ┆ 1]       │\n",
       "│           ┆ 18:26:38  ┆           ┆           ┆   ┆           ┆           ┆ …         ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ 9667800]  ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td></tr></thead><tbody><tr><td>3033563</td><td>&quot;Kniven for str…</td><td>&quot;I aftenens udg…</td><td>2023-06-29 06:20:47</td><td>false</td><td>&quot;Når man ser fj…</td><td>2007-03-27 10:22:08</td><td>[3005524, 3005525]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[]</td><td>414</td><td>[433, 436]</td><td>&quot;underholdning&quot;</td></tr><tr><td>3057640</td><td>&quot;Leths pige var…</td><td>&quot;Jørgen Leth æn…</td><td>2023-06-29 06:21:24</td><td>false</td><td>&quot;Filmmanden, fo…</td><td>2005-10-09 17:36:00</td><td>[3047111]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 16)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬──────────┬───────────┬───────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ topics    ┆ category ┆ subcatego ┆ category_ │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ ---       ┆ ---      ┆ ry        ┆ str       │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ list[str] ┆ i16      ┆ ---       ┆ ---       │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆           ┆          ┆ list[i16] ┆ str       │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆          ┆           ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪══════════╪═══════════╪═══════════╡\n",
       "│ 3033563   ┆ Kniven    ┆ I         ┆ 2023-06-2 ┆ … ┆ []        ┆ 414      ┆ [433,     ┆ underhold │\n",
       "│           ┆ for strub ┆ aftenens  ┆ 9         ┆   ┆           ┆          ┆ 436]      ┆ ning      │\n",
       "│           ┆ en-vært   ┆ udgave af ┆ 06:20:47  ┆   ┆           ┆          ┆           ┆           │\n",
       "│           ┆ får selv… ┆ 'Med      ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "│           ┆           ┆ kniven…   ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "│ 3057640   ┆ Leths     ┆ Jørgen    ┆ 2023-06-2 ┆ … ┆ []        ┆ 414      ┆ [432]     ┆ underhold │\n",
       "│           ┆ pige var  ┆ Leth      ┆ 9         ┆   ┆           ┆          ┆           ┆ ning      │\n",
       "│           ┆ ikke 17   ┆ ændrer nu ┆ 06:21:24  ┆   ┆           ┆          ┆           ┆           │\n",
       "│           ┆ men 19 år ┆ forklarin ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "│           ┆           ┆ g…        ┆           ┆   ┆           ┆          ┆           ┆           │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴──────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_articles = pl.read_parquet(path.joinpath(\"articles.parquet\"))\n",
    "df_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init model using HuggingFace's tokenizer and wordembedding\n",
    "In the original implementation, they use the GloVe embeddings and tokenizer. To get going fast, we'll use a multilingual LLM from Hugging Face. \n",
    "Utilizing the tokenizer to tokenize the articles and the word-embedding to init NRMS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the \n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "# \n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "# =>\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_articles, value_col=token_col_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate the dataloaders\n",
    "In the implementations we have disconnected the models and data. Hence, you should built a dataloader that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_train,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=False,\n",
    "    batch_size=64,\n",
    ")\n",
    "val_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_validation,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "test_dataloader = NRMSDataLoader(\n",
    "    behaviors=df_test,\n",
    "    article_dict=article_mapping,\n",
    "    unknown_representation=\"zeros\",\n",
    "    history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    eval_mode=True,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - ETA: 0s - loss: 1.6092"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"NRMS\"\n",
    "LOG_DIR = f\"downloads/runs/{MODEL_NAME}\"\n",
    "MODEL_WEIGHTS = f\"downloads/data/state_dict/{MODEL_NAME}/weights\"\n",
    "\n",
    "# CALLBACKS\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=MODEL_WEIGHTS, save_best_only=True, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "hparams_nrms.history_size = HISTORY_SIZE\n",
    "model = NRMSModel(\n",
    "    hparams=hparams_nrms,\n",
    "    word2vec_embedding=word2vec_embedding,\n",
    "    seed=42,\n",
    ")\n",
    "hist = model.model.fit(\n",
    "    train_dataloader,\n",
    "    validation_data=val_dataloader,\n",
    "    epochs=1,\n",
    "    callbacks=[tensorboard_callback, early_stopping, modelcheckpoint],\n",
    ")\n",
    "model = model.model.load_weights(filepath=MODEL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 8s 1s/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.scorer.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = add_prediction_scores(df_test, pred.tolist()).pipe(\n",
    "    add_known_user_column, known_users=df_train[DEFAULT_USER_COL]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example how to compute some metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.4516887234900142,\n",
       " 'mrr': 0.3148457418185679,\n",
       " 'ndcg@5': 0.35970396106087243,\n",
       " 'ndcg@10': 0.41935821814111035}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ebrec.evaluation import AucScore, MrrScore, MetricEvaluator, NdcgScore\n",
    "def compute_evaluation_scores(\n",
    "    df: pl.DataFrame,\n",
    "    metric_functions: list[MetricEvaluator] = [\n",
    "        AucScore(),\n",
    "        MrrScore(),\n",
    "        NdcgScore(k=5),\n",
    "        NdcgScore(k=10),\n",
    "    ],\n",
    "    pred_score = \"scores\",\n",
    "    labels:str=\"labels\"\n",
    ") -> dict[str, float]:\n",
    "    # =>\n",
    "    y_pred = df[pred_score].to_list()\n",
    "    y_true = df[labels].to_list()\n",
    "    # =>\n",
    "    metr = MetricEvaluator(\n",
    "        labels=y_true,\n",
    "        predictions=y_pred,\n",
    "        metric_functions=metric_functions,\n",
    "    )\n",
    "    return metr.evaluate().evaluations\n",
    "\n",
    "compute_evaluation_scores(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
