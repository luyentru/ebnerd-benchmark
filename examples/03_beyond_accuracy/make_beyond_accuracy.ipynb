{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello\n",
    "\n",
    "This notebook is an example of how to make a beyond-accuracy dataset, and how one could make baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._python import write_json_file, read_json_file\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "    DEFAULT_ARTICLE_MODIFIED_TIMESTAMP_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_SENTIMENT_SCORE_COL,\n",
    "    DEFAULT_SENTIMENT_LABEL_COL,\n",
    "    DEFAULT_TOTAL_INVIEWS_COL,\n",
    "    DEFAULT_IS_SUBSCRIBER_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_IS_SSO_USER_COL,\n",
    "    DEFAULT_ARTICLE_ID_COL,\n",
    "    DEFAULT_POSTCODE_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_GENDER_COL,\n",
    "    DEFAULT_USER_COL,\n",
    "    DEFAULT_AGE_COL,\n",
    ")\n",
    "\n",
    "from ebrec.evaluation.beyond_accuracy import (\n",
    "    IntralistDiversity,\n",
    "    Distribution,\n",
    "    Serendipity,\n",
    "    Sentiment,\n",
    "    Coverage,\n",
    "    Novelty,\n",
    ")\n",
    "\n",
    "from ebrec.utils._articles import create_sort_based_prediction_score\n",
    "from ebrec.utils._behaviors import truncate_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"evaluation_artifacts\"\n",
    "DATASET_SPLIT = \"test\"\n",
    "DATASET_SIZE = \"demo\"\n",
    "PATH = Path(f\"../downloads/{DATASET_SIZE}\")\n",
    "PATH_BEYOND_ACCURACY = PATH.joinpath(ROOT_FOLDER)\n",
    "PATH_BEYOND_ACCURACY.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# LOAD:\n",
    "df_beyond_accuarcy = pl.scan_parquet(\n",
    "    PATH.joinpath(DATASET_SPLIT, \"behaviors.parquet\")\n",
    ").filter(pl.col(\"is_beyond_accuracy\"))\n",
    "df_behaviors = pl.scan_parquet(\n",
    "    PATH.joinpath(DATASET_SPLIT, \"behaviors.parquet\")\n",
    ").filter(~pl.col(\"is_beyond_accuracy\"))\n",
    "df_articles = pl.scan_parquet(PATH.joinpath(\"articles.parquet\"))\n",
    "df_history = pl.scan_parquet(PATH.joinpath(DATASET_SPLIT, \"history.parquet\")).select(\n",
    "    DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output files for Beyond Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEYOND_ACCURACY_HISTORY_DICT = \"beyond_accuracy_history_dict.json\"\n",
    "BEYOND_ACCURACY_USERS_DICT = \"beyond_accuracy_users_dict.json\"\n",
    "CANDIDATE_LIST = \"candidate_list.json\"\n",
    "ARTICLES_DICT = \"articles_dict.json\"\n",
    "BEHAVIORS_TIMESTAMP_DICT = \"behaviors_timestamp_dict.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make / Dump Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make candidate list for beyond-accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the candidate list from the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Candidate IDs: 250 (example: [9793163, 9793069, 9792076, 9792749, 9791280])\n",
      "Dump: ../downloads/demo/evaluation_artifacts/candidate_list.json\n"
     ]
    }
   ],
   "source": [
    "candidate_list = (\n",
    "    df_beyond_accuarcy.select(pl.col(DEFAULT_INVIEW_ARTICLES_COL).first())\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")[0].to_list()\n",
    "write_json_file(candidate_list, PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST))\n",
    "\n",
    "print(f\"Number of Candidate IDs: {len(candidate_list)} (example: {candidate_list[:5]})\")\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santity check - passed\n"
     ]
    }
   ],
   "source": [
    "load_candidate_list = read_json_file(PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST))\n",
    "if (\n",
    "    not (\n",
    "        df_beyond_accuarcy.select(DEFAULT_INVIEW_ARTICLES_COL).collect()\n",
    "        == candidate_list\n",
    "    )\n",
    "    .sum()[DEFAULT_INVIEW_ARTICLES_COL]\n",
    "    .to_list()[0]\n",
    "    == df_beyond_accuarcy.select(DEFAULT_INVIEW_ARTICLES_COL).collect().shape[0]\n",
    "):\n",
    "    raise ValueError(\"candidate_list is not identical in the testset\")\n",
    "\n",
    "if not (np.array(candidate_list) - np.array(load_candidate_list)).sum() == 0:\n",
    "    raise ValueError(\"candidate_list was not dump correctly\")\n",
    "\n",
    "print(\"santity check - passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User meta data: Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: ../downloads/demo/evaluation_artifacts/beyond_accuracy_users_dict.json\n",
      "#rows: 1615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>is_subscriber</th><th>is_sso_user</th><th>postcode</th><th>gender</th><th>age</th></tr><tr><td>bool</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>true</td><td>true</td><td>null</td><td>0</td><td>30</td></tr><tr><td>true</td><td>true</td><td>null</td><td>null</td><td>null</td></tr><tr><td>true</td><td>true</td><td>null</td><td>0</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌───────────────┬─────────────┬──────────┬────────┬──────┐\n",
       "│ is_subscriber ┆ is_sso_user ┆ postcode ┆ gender ┆ age  │\n",
       "│ ---           ┆ ---         ┆ ---      ┆ ---    ┆ ---  │\n",
       "│ bool          ┆ bool        ┆ i8       ┆ i8     ┆ i8   │\n",
       "╞═══════════════╪═════════════╪══════════╪════════╪══════╡\n",
       "│ true          ┆ true        ┆ null     ┆ 0      ┆ 30   │\n",
       "│ true          ┆ true        ┆ null     ┆ null   ┆ null │\n",
       "│ true          ┆ true        ┆ null     ┆ 0      ┆ null │\n",
       "└───────────────┴─────────────┴──────────┴────────┴──────┘"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_meta_columns = [\n",
    "    DEFAULT_IS_SUBSCRIBER_COL,\n",
    "    DEFAULT_IS_SSO_USER_COL,\n",
    "    DEFAULT_POSTCODE_COL,\n",
    "    DEFAULT_GENDER_COL,\n",
    "    DEFAULT_AGE_COL,\n",
    "]\n",
    "df_users = df_beyond_accuarcy.select(pl.col(user_meta_columns)).collect()\n",
    "\n",
    "users_dict = {col: df_users[col].to_list() for col in df_users.columns}\n",
    "write_json_file(users_dict, PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_USERS_DICT))\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_USERS_DICT)}\")\n",
    "\n",
    "print(f\"#rows: {df_users.shape[0]}\")\n",
    "df_users.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: ../downloads/demo/evaluation_artifacts/beyond_accuracy_history_dict.json\n",
      "#rows: 1615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>user_id</th><th>article_id_fixed</th></tr><tr><td>u32</td><td>list[i32]</td></tr></thead><tbody><tr><td>1744285</td><td>[9789494, 9788516, … 9790700]</td></tr><tr><td>631807</td><td>[9790827, 9790811, … 9790804]</td></tr><tr><td>1984028</td><td>[9790827, 9776147, … 9789896]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 2)\n",
       "┌─────────┬───────────────────────────────┐\n",
       "│ user_id ┆ article_id_fixed              │\n",
       "│ ---     ┆ ---                           │\n",
       "│ u32     ┆ list[i32]                     │\n",
       "╞═════════╪═══════════════════════════════╡\n",
       "│ 1744285 ┆ [9789494, 9788516, … 9790700] │\n",
       "│ 631807  ┆ [9790827, 9790811, … 9790804] │\n",
       "│ 1984028 ┆ [9790827, 9776147, … 9789896] │\n",
       "└─────────┴───────────────────────────────┘"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HISTORY_SIZE = 5\n",
    "\n",
    "df_user_histoies = (\n",
    "    df_beyond_accuarcy.select(DEFAULT_USER_COL)\n",
    "    .join(df_history, on=DEFAULT_USER_COL, how=\"left\")\n",
    "    .pipe(\n",
    "        truncate_history,\n",
    "        column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "        history_size=HISTORY_SIZE,\n",
    "        padding_value=None,\n",
    "        enable_warning=False,\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "user_history_dict = {\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL: df_user_histoies[\n",
    "        DEFAULT_HISTORY_ARTICLE_ID_COL\n",
    "    ].to_list()\n",
    "}\n",
    "write_json_file(\n",
    "    user_history_dict, PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_HISTORY_DICT)\n",
    ")\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_HISTORY_DICT)}\")\n",
    "\n",
    "print(f\"#rows: {df_user_histoies.shape[0]}\")\n",
    "df_user_histoies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp for Behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used for computing the AUC as function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: ../downloads/demo/evaluation_artifacts/behaviors_timestamp_dict.json\n",
      "#rows: 27052\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>impression_time</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;2023-06-05 15:…</td></tr><tr><td>&quot;2023-06-05 15:…</td></tr><tr><td>&quot;2023-06-01 10:…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 1)\n",
       "┌────────────────────────────┐\n",
       "│ impression_time            │\n",
       "│ ---                        │\n",
       "│ str                        │\n",
       "╞════════════════════════════╡\n",
       "│ 2023-06-05 15:18:16.000000 │\n",
       "│ 2023-06-05 15:36:07.000000 │\n",
       "│ 2023-06-01 10:25:38.000000 │\n",
       "└────────────────────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_behaviors_timestamp = df_behaviors.select(\n",
    "    pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).cast(pl.Utf8),\n",
    ").collect()\n",
    "behaviors_timestamp_dict = {\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL: df_behaviors_timestamp[\n",
    "        DEFAULT_IMPRESSION_TIMESTAMP_COL\n",
    "    ].to_list()\n",
    "}\n",
    "write_json_file(\n",
    "    behaviors_timestamp_dict, PATH_BEYOND_ACCURACY.joinpath(BEHAVIORS_TIMESTAMP_DICT)\n",
    ")\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(BEHAVIORS_TIMESTAMP_DICT)}\")\n",
    "print(f\"#rows: {df_behaviors_timestamp.shape[0]}\")\n",
    "df_behaviors_timestamp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Candidate lookup dict / Dump lookup dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles to include: *candidate-list* and *history-articles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_article_id = (\n",
    "    df_user_histoies.lazy()\n",
    "    .select(pl.col(DEFAULT_HISTORY_ARTICLE_ID_COL).explode().unique())\n",
    "    .collect()[DEFAULT_HISTORY_ARTICLE_ID_COL]\n",
    "    .to_list()\n",
    ")\n",
    "article_ids = candidate_list + history_article_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select articles that should be included in the lookup dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_TOTAL_PAGEVIEWS_COL_NORMALIZED_MAX = (\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL + \"_normalized_max\"\n",
    ")\n",
    "DEFAULT_TOTAL_PAGEVIEWS_COL_NORMALIZED_MIN_MAX = (\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL + \"_normalized_min_max\"\n",
    ")\n",
    "# =>\n",
    "df_lookup_articles = (\n",
    "    df_articles.filter(pl.col(DEFAULT_ARTICLE_ID_COL).is_in(article_ids))\n",
    "    .with_columns(\n",
    "        pl.col(\n",
    "            DEFAULT_ARTICLE_MODIFIED_TIMESTAMP_COL,\n",
    "            DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "        ).cast(pl.Utf8)\n",
    "    )\n",
    "    # Zeros might cause issues\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_TOTAL_INVIEWS_COL, DEFAULT_TOTAL_PAGEVIEWS_COL).fill_null(1)\n",
    "    )\n",
    "    # SIMPLE NORMALIZATION: x / max()\n",
    "    .with_columns(\n",
    "        (\n",
    "            pl.col(DEFAULT_TOTAL_PAGEVIEWS_COL)\n",
    "            / pl.col(DEFAULT_TOTAL_PAGEVIEWS_COL).max()\n",
    "        ).alias(DEFAULT_TOTAL_PAGEVIEWS_COL_NORMALIZED_MAX)\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# _min = df_lookup_articles[DEFAULT_TOTAL_PAGEVIEWS_COL].min()\n",
    "# _max = df_lookup_articles[DEFAULT_TOTAL_PAGEVIEWS_COL].max()\n",
    "\n",
    "# df_lookup_articles = df_lookup_articles.with_columns(\n",
    "#     (\n",
    "#         1\n",
    "#         + (\n",
    "#             (\n",
    "#                 pl.col(DEFAULT_TOTAL_PAGEVIEWS_COL)\n",
    "#                 - pl.col(DEFAULT_TOTAL_PAGEVIEWS_COL).min()\n",
    "#             )\n",
    "#             * (\n",
    "#                 (df_lookup_articles.shape[0] - 1)\n",
    "#                 / (max - pl.col(DEFAULT_TOTAL_PAGEVIEWS_COL).min())\n",
    "#             )\n",
    "#         )\n",
    "#     ).alias(DEFAULT_TOTAL_PAGEVIEWS_COL_NORMALIZED_MIN_MAX)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lookup_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#rows: 1282\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 24)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th><th>total_pageviews_normalized_max</th><th>contrastive_vector</th><th>document_vector</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td><td>f64</td><td>list[f32]</td><td>list[f32]</td></tr></thead><tbody><tr><td>3971783</td><td>&quot;Paradise-Maria…</td><td>&quot;Reality-deltag…</td><td>&quot;2023-06-29 06:…</td><td>false</td><td>&quot;Paradise Hotel…</td><td>&quot;2013-04-17 17:…</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, … &quot;Reality&quot;]</td><td>414</td><td>[425]</td><td>&quot;underholdning&quot;</td><td>1</td><td>1</td><td>null</td><td>0.959</td><td>&quot;Negative&quot;</td><td>0.000001</td><td>[-0.008399, 0.025603, … 0.021549]</td><td>[0.046812, 0.012343, … 0.005147]</td></tr><tr><td>4280152</td><td>&quot;Hjælp Fogh med…</td><td>&quot;Kongehuset med…</td><td>&quot;2023-06-29 06:…</td><td>false</td><td>&quot;Danmarks stats…</td><td>&quot;2009-04-08 09:…</td><td>[3423769]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Anders Fogh Rasmussen&quot;]</td><td>[&quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Politik&quot;, &quot;National politik&quot;]</td><td>512</td><td>[]</td><td>&quot;nationen&quot;</td><td>1</td><td>1</td><td>null</td><td>0.6137</td><td>&quot;Positive&quot;</td><td>0.000001</td><td>[0.000427, 0.010277, … -0.009518]</td><td>[-0.023408, 0.01755, … 0.020888]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 24)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ sentiment ┆ total_pag ┆ contrasti ┆ document │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ _label    ┆ eviews_no ┆ ve_vector ┆ _vector  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ rmalized_ ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ str       ┆   ┆ str       ┆ max       ┆ list[f32] ┆ list[f32 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ ---       ┆           ┆ ]        │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ f64       ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3971783   ┆ Paradise- ┆ Reality-d ┆ 2023-06-2 ┆ … ┆ Negative  ┆ 0.000001  ┆ [-0.00839 ┆ [0.04681 │\n",
       "│           ┆ Maria     ┆ eltageren ┆ 9 06:27:0 ┆   ┆           ┆           ┆ 9,        ┆ 2, 0.012 │\n",
       "│           ┆ vred på   ┆ skælder   ┆ 7.000000  ┆   ┆           ┆           ┆ 0.025603, ┆ 343, …   │\n",
       "│           ┆ TV3: De   ┆ ud på…    ┆           ┆   ┆           ┆           ┆ …         ┆ 0.005147 │\n",
       "│           ┆ s…        ┆           ┆           ┆   ┆           ┆           ┆ 0.021549… ┆ ]        │\n",
       "│ 4280152   ┆ Hjælp     ┆ Kongehuse ┆ 2023-06-2 ┆ … ┆ Positive  ┆ 0.000001  ┆ [0.000427 ┆ [-0.0234 │\n",
       "│           ┆ Fogh med  ┆ t         ┆ 9 06:48:0 ┆   ┆           ┆           ┆ ,         ┆ 08,      │\n",
       "│           ┆ skjold og ┆ meddeler, ┆ 8.000000  ┆   ┆           ┆           ┆ 0.010277, ┆ 0.01755, │\n",
       "│           ┆ valgspr…  ┆ at        ┆           ┆   ┆           ┆           ┆ … -0.0095 ┆ … 0.0208 │\n",
       "│           ┆           ┆ statsmin… ┆           ┆   ┆           ┆           ┆ 18…       ┆ 88]      │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# => Embeddings:\n",
    "BERT_VECTOR = \"bert_base_multilingual_cased\"\n",
    "ROBERTA_VECTOR = \"xlm_roberta_base\"\n",
    "\n",
    "CONTRASTIVE_VECTOR = \"contrastive_vector\"\n",
    "DOCUMENT_VECTOR = \"document_vector\"\n",
    "\n",
    "\n",
    "def load_join_embeddings(df: pl.DataFrame, emb_path: Path) -> pl.DataFrame:\n",
    "    emb_contrastive = (\n",
    "        pl.scan_parquet(PATH.parent.joinpath(emb_path))\n",
    "        .filter(pl.col(DEFAULT_ARTICLE_ID_COL).is_in(df.select(DEFAULT_ARTICLE_ID_COL)))\n",
    "        .collect()\n",
    "    )\n",
    "    return df.join(emb_contrastive, on=DEFAULT_ARTICLE_ID_COL, how=\"left\")\n",
    "\n",
    "\n",
    "df_lookup_articles = df_lookup_articles.pipe(\n",
    "    load_join_embeddings,\n",
    "    emb_path=f\"embeddings/Ekstra_Bladet_contrastive_vector/{CONTRASTIVE_VECTOR}.parquet\",\n",
    ").pipe(\n",
    "    load_join_embeddings,\n",
    "    emb_path=f\"embeddings/Ekstra_Bladet_word2vec/{DOCUMENT_VECTOR}.parquet\",\n",
    ")\n",
    "print(f\"#rows: {df_lookup_articles.shape[0]}\")\n",
    "df_lookup_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to lookup dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#articles: 1282\n",
      "Dump: ../downloads/demo/evaluation_artifacts/articles_dict.json\n"
     ]
    }
   ],
   "source": [
    "articles_dict = {}\n",
    "for row in df_lookup_articles.iter_rows(named=True):\n",
    "    # Note, all keys in dictionaries are converted to strings, when serializing an object to JSON format.\n",
    "    articles_dict[str(row[DEFAULT_ARTICLE_ID_COL])] = row\n",
    "# Write it:\n",
    "write_json_file(articles_dict, PATH_BEYOND_ACCURACY.joinpath(ARTICLES_DICT))\n",
    "print(f\"#articles: {len(articles_dict)}\")\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(ARTICLES_DICT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a couple *Baselines* based on the candidate-list:\n",
    "1. @EditorialPicks: We approximate this based on the number **inview** an articles have recived. Ekstra Bladet is front-page driven, meaning, if an article has a lot of inview-impression (seen) a lot, we believe it has been selected to be in a top priority from the editors. This is static (it does change for our *candidate_list*), i.e., the computation is done once.\n",
    "2. @Popular: We approximate this based on the number **clicks** an articles have recived. This is static (it does change for our *candidate_list*), i.e., the computation is done once.\n",
    "3. @Random: Simple baseline and important baseline. We simple pick a set of *top-n* articles from the *candidate-list* and run multiple times.\n",
    "4. @Dissimilarity / Similarity (will come later): Select top-n articles that are the most similar / dissimilar. \n",
    "5. @Newest: Simply pick the newest released articles. We do see newssite where the top banner is *Newest released*. We include it, but note this is very sensitive and might not be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#behaviors_timestamp_dict: 27052\n",
      "#history_dict: 1615\n",
      " history_dict.keys(): dict_keys(['article_id_fixed'])\n",
      "#users_dict 1615\n",
      " users_dict.keys(): dict_keys(['is_subscriber', 'is_sso_user', 'postcode', 'gender', 'age'])\n",
      "#user_history_dict 1615\n",
      " users_dict.keys(): dict_keys(['article_id_fixed'])\n",
      "#articles_dict: 1282\n",
      " articles_dict[ID].keys(): dict_keys(['article_id', 'title', 'subtitle', 'last_modified_time', 'premium', 'body', 'published_time', 'image_ids', 'article_type', 'url', 'ner_clusters', 'entity_groups', 'topics', 'category', 'subcategory', 'category_str', 'total_inviews', 'total_pageviews', 'total_read_time', 'sentiment_score', 'sentiment_label', 'total_pageviews_normalized_max', 'contrastive_vector', 'document_vector'])\n",
      "#candidate_list: 154\n"
     ]
    }
   ],
   "source": [
    "def n_items(d) -> int:\n",
    "    return len(d[list(d)[0]])\n",
    "\n",
    "\n",
    "# =>\n",
    "behaviors_timestamp_dict = read_json_file(\n",
    "    PATH_BEYOND_ACCURACY.joinpath(BEHAVIORS_TIMESTAMP_DICT)\n",
    ")\n",
    "print(f\"#behaviors_timestamp_dict: {n_items(behaviors_timestamp_dict)}\")\n",
    "\n",
    "# =>\n",
    "history_dict = read_json_file(\n",
    "    PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_HISTORY_DICT)\n",
    ")\n",
    "print(\n",
    "    f\"#history_dict: {n_items(history_dict)}\\n history_dict.keys(): {history_dict.keys()}\"\n",
    ")\n",
    "\n",
    "# =>\n",
    "users_dict = read_json_file(PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_USERS_DICT))\n",
    "print(f\"#users_dict {n_items(users_dict)}\\n users_dict.keys(): {users_dict.keys()}\")\n",
    "\n",
    "# =>\n",
    "user_history_dict = read_json_file(\n",
    "    PATH_BEYOND_ACCURACY.joinpath(BEYOND_ACCURACY_HISTORY_DICT)\n",
    ")\n",
    "print(\n",
    "    f\"#user_history_dict {n_items(user_history_dict)}\\n users_dict.keys(): {user_history_dict.keys()}\"\n",
    ")\n",
    "\n",
    "# =>\n",
    "articles_dict = {\n",
    "    int(key): val\n",
    "    for key, val in read_json_file(PATH_BEYOND_ACCURACY.joinpath(ARTICLES_DICT)).items()\n",
    "}\n",
    "aid_keys = articles_dict[list(articles_dict)[0]].keys()\n",
    "print(f\"#articles_dict: {len(articles_dict)}\\n articles_dict[ID].keys(): {aid_keys}\")\n",
    "\n",
    "# => Only the once actually found in the dataset (for demo only 154 of 250 are represent)\n",
    "candidate_list = [\n",
    "    id\n",
    "    for id in read_json_file(PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST))\n",
    "    if id in list(articles_dict)\n",
    "]\n",
    "print(f\"#candidate_list: {len(candidate_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Ranked Candidate lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editorical Pick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬───────────────┬──────────────────┐\n",
      "│ article_id ┆ total_inviews ┆ prediction_score │\n",
      "│ ---        ┆ ---           ┆ ---              │\n",
      "│ i32        ┆ i32           ┆ f64              │\n",
      "╞════════════╪═══════════════╪══════════════════╡\n",
      "│ 9777983    ┆ 3889163       ┆ 1.0              │\n",
      "│ 9777339    ┆ 3825801       ┆ 0.5              │\n",
      "└────────────┴───────────────┴──────────────────┘\n",
      "[[9777983 9777339]]\n"
     ]
    }
   ],
   "source": [
    "df_candidates_editorial_picks = create_sort_based_prediction_score(\n",
    "    df_lookup_articles, column=DEFAULT_TOTAL_INVIEWS_COL, desc=True\n",
    ")\n",
    "candidates_editorial_picks = np.array(\n",
    "    [df_candidates_editorial_picks.select(DEFAULT_ARTICLE_ID_COL).to_series()]\n",
    ")\n",
    "# =>\n",
    "print(df_candidates_editorial_picks.head(2))\n",
    "print(candidates_editorial_picks[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬─────────────────┬──────────────────┐\n",
      "│ article_id ┆ total_pageviews ┆ prediction_score │\n",
      "│ ---        ┆ ---             ┆ ---              │\n",
      "│ i32        ┆ i32             ┆ f64              │\n",
      "╞════════════╪═════════════════╪══════════════════╡\n",
      "│ 9765641    ┆ 762726          ┆ 1.0              │\n",
      "│ 9765410    ┆ 410966          ┆ 0.5              │\n",
      "└────────────┴─────────────────┴──────────────────┘\n",
      "[[9765641 9765410]]\n"
     ]
    }
   ],
   "source": [
    "df_candidates_popular = create_sort_based_prediction_score(\n",
    "    df_lookup_articles, column=DEFAULT_TOTAL_PAGEVIEWS_COL, desc=True\n",
    ")\n",
    "candidates_popular = np.array(\n",
    "    [df_candidates_popular.select(DEFAULT_ARTICLE_ID_COL).to_series()]\n",
    ")\n",
    "# =>\n",
    "print(df_candidates_popular.head(2))\n",
    "print(candidates_popular[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬────────────────────────────┬──────────────────┐\n",
      "│ article_id ┆ published_time             ┆ prediction_score │\n",
      "│ ---        ┆ ---                        ┆ ---              │\n",
      "│ i32        ┆ str                        ┆ f64              │\n",
      "╞════════════╪════════════════════════════╪══════════════════╡\n",
      "│ 4802444    ┆ 2007-10-30 08:16:59.000000 ┆ 1.0              │\n",
      "│ 4327174    ┆ 2008-07-16 12:18:50.000000 ┆ 0.5              │\n",
      "└────────────┴────────────────────────────┴──────────────────┘\n",
      "[[4802444 4327174]]\n"
     ]
    }
   ],
   "source": [
    "df_candidates_newest = create_sort_based_prediction_score(\n",
    "    df_lookup_articles, column=DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL, desc=False\n",
    ")\n",
    "candidates_newest = np.array(\n",
    "    [df_candidates_newest.select(DEFAULT_ARTICLE_ID_COL).to_series()]\n",
    ")\n",
    "# =>\n",
    "print(df_candidates_newest.head(2))\n",
    "print(candidates_newest[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "instralist_diversity = IntralistDiversity()\n",
    "distribution = Distribution()\n",
    "serendipity = Serendipity()\n",
    "sentiment = Sentiment()\n",
    "coverage = Coverage()\n",
    "novelty = Novelty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Baselines (and your model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#random-iterations: 1615\n",
      "Top@5 ranked articles\n"
     ]
    }
   ],
   "source": [
    "RANDOM_ITER = df_beyond_accuarcy.select(DEFAULT_INVIEW_ARTICLES_COL).collect().shape[0]\n",
    "TOP_N = 5\n",
    "\n",
    "np.random.seed(123)\n",
    "# Make list:\n",
    "top_n_candidates_random = [\n",
    "    np.random.choice(candidate_list, size=TOP_N, replace=False)\n",
    "    for _ in range(RANDOM_ITER)\n",
    "]\n",
    "top_n_candidates_editorial_picks = candidates_editorial_picks[:, :TOP_N]\n",
    "top_n_candidates_popular = candidates_popular[:, :TOP_N]\n",
    "top_n_candidates_newest = candidates_newest[:, :TOP_N]\n",
    "#\n",
    "# Set them as tuples, just to loop through it:\n",
    "candidates_name_pairs = [\n",
    "    [top_n_candidates_editorial_picks, \"editorial_picks\"],\n",
    "    [top_n_candidates_popular, \"popular\"],\n",
    "    [top_n_candidates_random, \"random\"],\n",
    "    [top_n_candidates_newest, \"newest\"],\n",
    "]\n",
    "# =>\n",
    "user_history = user_history_dict[DEFAULT_HISTORY_ARTICLE_ID_COL]\n",
    "\n",
    "print(f\"#random-iterations: {RANDOM_ITER}\")\n",
    "print(f\"Top@{TOP_N} ranked articles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Model\n",
    "Try to add your model's prediction of the candidate list. In this notebook we just take a random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_your_model = [\n",
    "    np.random.choice(candidate_list, size=TOP_N, replace=False)\n",
    "    for _ in range(RANDOM_ITER)\n",
    "]\n",
    "candidates_name_pairs.append([candidates_your_model, \"random_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instralist-Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>editorial_picks_intralist_diversity</th><th>popular_intralist_diversity</th><th>random_intralist_diversity</th><th>newest_intralist_diversity</th><th>random_2_intralist_diversity</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.82719</td><td>0.857918</td><td>0.790407</td><td>0.74301</td><td>0.778713</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌───────────────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│ editorial_picks_i ┆ popular_intralist ┆ random_intralist_ ┆ newest_intralist_ ┆ random_2_intrali │\n",
       "│ ntralist_divers…  ┆ _diversity        ┆ diversity         ┆ diversity         ┆ st_diversity     │\n",
       "│ ---               ┆ ---               ┆ ---               ┆ ---               ┆ ---              │\n",
       "│ f64               ┆ f64               ┆ f64               ┆ f64               ┆ f64              │\n",
       "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════════════╡\n",
       "│ 0.82719           ┆ 0.857918          ┆ 0.790407          ┆ 0.74301           ┆ 0.778713         │\n",
       "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instralist_diversity_dict = {\n",
    "    f\"{list_name}_{instralist_diversity.name}\": instralist_diversity(\n",
    "        candidates,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=CONTRASTIVE_VECTOR,\n",
    "    )[0]\n",
    "    for candidates, list_name in candidates_name_pairs\n",
    "}\n",
    "pl.DataFrame(instralist_diversity_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The embedding representation\n",
    "This might be obvious, but the embedding representation used for computing a metric is very influential. Hence, baselines are important to determine high and low scores. Also, this is why these metrics can be very hard to interpret for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrastive_vector: 0.8271895467942351\n",
      "document_vector: 0.18989835319860843\n"
     ]
    }
   ],
   "source": [
    "ROBERTA_EMB = \"FacebookAI/xlm-roberta-base\"\n",
    "BERT_EMB = \"google-bert/bert-base-multilingual-cased\"\n",
    "print(\n",
    "    f\"{CONTRASTIVE_VECTOR}: {instralist_diversity(top_n_candidates_editorial_picks, lookup_dict=articles_dict, lookup_key=CONTRASTIVE_VECTOR)[0]}\"\n",
    ")\n",
    "print(\n",
    "    f\"{DOCUMENT_VECTOR}: {instralist_diversity(top_n_candidates_editorial_picks, lookup_dict=articles_dict, lookup_key=DOCUMENT_VECTOR)[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>editorial_picks_sentiment</th><th>popular_sentiment</th><th>random_sentiment</th><th>newest_sentiment</th><th>random_2_sentiment</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.89886</td><td>0.8884</td><td>0.895</td><td>0.80876</td><td>0.92832</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌────────────────────┬───────────────────┬──────────────────┬──────────────────┬───────────────────┐\n",
       "│ editorial_picks_se ┆ popular_sentiment ┆ random_sentiment ┆ newest_sentiment ┆ random_2_sentimen │\n",
       "│ ntiment            ┆ ---               ┆ ---              ┆ ---              ┆ t                 │\n",
       "│ ---                ┆ f64               ┆ f64              ┆ f64              ┆ ---               │\n",
       "│ f64                ┆                   ┆                  ┆                  ┆ f64               │\n",
       "╞════════════════════╪═══════════════════╪══════════════════╪══════════════════╪═══════════════════╡\n",
       "│ 0.89886            ┆ 0.8884            ┆ 0.895            ┆ 0.80876          ┆ 0.92832           │\n",
       "└────────────────────┴───────────────────┴──────────────────┴──────────────────┴───────────────────┘"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict = {\n",
    "    f\"{list_name}_{sentiment.name}\": sentiment(\n",
    "        candidates,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=DEFAULT_SENTIMENT_SCORE_COL,\n",
    "    )[0]\n",
    "    for candidates, list_name in candidates_name_pairs\n",
    "}\n",
    "pl.DataFrame(sentiment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serendipity\n",
    "When computing Serendipity it using the user's history; similarity between recommendations and browsed items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>editorial_picks_serendipity</th><th>popular_serendipity</th><th>random_serendipity</th><th>newest_serendipity</th><th>random_2_serendipity</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.822211</td><td>0.828664</td><td>0.790837</td><td>0.786472</td><td>0.790937</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌───────────────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
       "│ editorial_picks_s ┆ popular_serendipi ┆ random_serendipit ┆ newest_serendipit ┆ random_2_serendi │\n",
       "│ erendipity        ┆ ty                ┆ y                 ┆ y                 ┆ pity             │\n",
       "│ ---               ┆ ---               ┆ ---               ┆ ---               ┆ ---              │\n",
       "│ f64               ┆ f64               ┆ f64               ┆ f64               ┆ f64              │\n",
       "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════════════╡\n",
       "│ 0.822211          ┆ 0.828664          ┆ 0.790837          ┆ 0.786472          ┆ 0.790937         │\n",
       "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ADD USER HISTORY\n",
    "serendipity_dict = {}\n",
    "for candidates, list_name in candidates_name_pairs:\n",
    "    if len(candidates) == 1:\n",
    "        candidates = np.tile(candidates, len(user_history)).reshape(-1, TOP_N)\n",
    "    #\n",
    "    serendipity_dict[f\"{list_name}_{serendipity.name}\"] = serendipity(\n",
    "        candidates,\n",
    "        H=user_history,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=CONTRASTIVE_VECTOR,\n",
    "    ).mean()\n",
    "\n",
    "pl.DataFrame(serendipity_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty [Novelty SCORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>editorial_picks_novelty</th><th>popular_novelty</th><th>random_novelty</th><th>newest_novelty</th><th>random_2_novelty</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>3.272347</td><td>0.803791</td><td>3.446373</td><td>19.540805</td><td>3.618499</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 5)\n",
       "┌─────────────────────────┬─────────────────┬────────────────┬────────────────┬──────────────────┐\n",
       "│ editorial_picks_novelty ┆ popular_novelty ┆ random_novelty ┆ newest_novelty ┆ random_2_novelty │\n",
       "│ ---                     ┆ ---             ┆ ---            ┆ ---            ┆ ---              │\n",
       "│ f64                     ┆ f64             ┆ f64            ┆ f64            ┆ f64              │\n",
       "╞═════════════════════════╪═════════════════╪════════════════╪════════════════╪══════════════════╡\n",
       "│ 3.272347                ┆ 0.803791        ┆ 3.446373       ┆ 19.540805      ┆ 3.618499         │\n",
       "└─────────────────────────┴─────────────────┴────────────────┴────────────────┴──────────────────┘"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novelty_dict = {\n",
    "    f\"{list_name}_{novelty.name}\": novelty(\n",
    "        candidates,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=DEFAULT_TOTAL_PAGEVIEWS_COL_NORMALIZED_MAX,\n",
    "    )[0]\n",
    "    for candidates, list_name in candidates_name_pairs\n",
    "}\n",
    "pl.DataFrame(novelty_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>editorial_picks_coverage</th><th>popular_coverage</th><th>random_coverage</th><th>newest_coverage</th><th>random_2_coverage</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>5.0</td><td>5.0</td><td>154.0</td><td>5.0</td><td>154.0</td></tr><tr><td>&quot;fraction&quot;</td><td>0.032468</td><td>0.032468</td><td>1.0</td><td>0.032468</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 6)\n",
       "┌──────────┬─────────────────┬─────────────────┬─────────────────┬────────────────┬────────────────┐\n",
       "│ name     ┆ editorial_picks ┆ popular_coverag ┆ random_coverage ┆ newest_coverag ┆ random_2_cover │\n",
       "│ ---      ┆ _coverage       ┆ e               ┆ ---             ┆ e              ┆ age            │\n",
       "│ str      ┆ ---             ┆ ---             ┆ f64             ┆ ---            ┆ ---            │\n",
       "│          ┆ f64             ┆ f64             ┆                 ┆ f64            ┆ f64            │\n",
       "╞══════════╪═════════════════╪═════════════════╪═════════════════╪════════════════╪════════════════╡\n",
       "│ count    ┆ 5.0             ┆ 5.0             ┆ 154.0           ┆ 5.0            ┆ 154.0          │\n",
       "│ fraction ┆ 0.032468        ┆ 0.032468        ┆ 1.0             ┆ 0.032468       ┆ 1.0            │\n",
       "└──────────┴─────────────────┴─────────────────┴─────────────────┴────────────────┴────────────────┘"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_dict = {\"name\": [\"count\", \"fraction\"]}\n",
    "for candidates, list_name in candidates_name_pairs:\n",
    "    coverage_dict[f\"{list_name}_{coverage.name}\"] = coverage(candidates, candidate_list)\n",
    "\n",
    "pl.DataFrame(coverage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution - Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_distribution_dict(d: dict) -> dict:\n",
    "    return (\n",
    "        pl.concat(\n",
    "            [pl.DataFrame(val) for val in d.values()],\n",
    "            how=\"diagonal\",\n",
    "        )\n",
    "        .with_row_index(name=\"name\")\n",
    "        .with_columns(pl.Series(novelty_dict.keys()).alias(\"name\"))\n",
    "    ).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>underholdning</th><th>biler</th><th>krimi</th><th>forbrug</th><th>nyheder</th><th>musik</th><th>sport</th><th>penge</th><th>nationen</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;editorial_pick…</td><td>0.2</td><td>0.2</td><td>0.4</td><td>0.2</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;popular_novelt…</td><td>null</td><td>null</td><td>0.4</td><td>null</td><td>0.4</td><td>0.2</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;random_novelty…</td><td>0.133746</td><td>null</td><td>0.150217</td><td>0.019938</td><td>0.263158</td><td>0.058452</td><td>0.272941</td><td>0.062539</td><td>0.039009</td></tr><tr><td>&quot;newest_novelty…</td><td>0.4</td><td>null</td><td>0.4</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.2</td></tr><tr><td>&quot;random_2_novel…</td><td>0.134985</td><td>null</td><td>0.145759</td><td>0.022415</td><td>0.262167</td><td>0.056223</td><td>0.27839</td><td>0.061176</td><td>0.038885</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 10)\n",
       "┌───────────────┬───────────────┬───────┬──────────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
       "│ name          ┆ underholdning ┆ biler ┆ krimi    ┆ … ┆ musik    ┆ sport    ┆ penge    ┆ nationen │\n",
       "│ ---           ┆ ---           ┆ ---   ┆ ---      ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str           ┆ f64           ┆ f64   ┆ f64      ┆   ┆ f64      ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞═══════════════╪═══════════════╪═══════╪══════════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
       "│ editorial_pic ┆ 0.2           ┆ 0.2   ┆ 0.4      ┆ … ┆ null     ┆ null     ┆ null     ┆ null     │\n",
       "│ ks_novelty    ┆               ┆       ┆          ┆   ┆          ┆          ┆          ┆          │\n",
       "│ popular_novel ┆ null          ┆ null  ┆ 0.4      ┆ … ┆ 0.2      ┆ null     ┆ null     ┆ null     │\n",
       "│ ty            ┆               ┆       ┆          ┆   ┆          ┆          ┆          ┆          │\n",
       "│ random_novelt ┆ 0.133746      ┆ null  ┆ 0.150217 ┆ … ┆ 0.058452 ┆ 0.272941 ┆ 0.062539 ┆ 0.039009 │\n",
       "│ y             ┆               ┆       ┆          ┆   ┆          ┆          ┆          ┆          │\n",
       "│ newest_novelt ┆ 0.4           ┆ null  ┆ 0.4      ┆ … ┆ null     ┆ null     ┆ null     ┆ 0.2      │\n",
       "│ y             ┆               ┆       ┆          ┆   ┆          ┆          ┆          ┆          │\n",
       "│ random_2_nove ┆ 0.134985      ┆ null  ┆ 0.145759 ┆ … ┆ 0.056223 ┆ 0.27839  ┆ 0.061176 ┆ 0.038885 │\n",
       "│ lty           ┆               ┆       ┆          ┆   ┆          ┆          ┆          ┆          │\n",
       "└───────────────┴───────────────┴───────┴──────────┴───┴──────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMN = DEFAULT_CATEGORY_STR_COL\n",
    "\n",
    "distribution_dict = {\n",
    "    f\"{list_name}_{novelty.name}\": distribution(\n",
    "        candidates,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=COLUMN,\n",
    "    )\n",
    "    for candidates, list_name in candidates_name_pairs\n",
    "}\n",
    "\n",
    "distribution_category_dict = concat_distribution_dict(distribution_dict)\n",
    "pl.DataFrame(distribution_category_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>Positive</th><th>Neutral</th><th>Negative</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;editorial_pick…</td><td>0.4</td><td>0.2</td><td>0.4</td></tr><tr><td>&quot;popular_novelt…</td><td>0.2</td><td>null</td><td>0.8</td></tr><tr><td>&quot;random_novelty…</td><td>0.172136</td><td>0.275046</td><td>0.552817</td></tr><tr><td>&quot;newest_novelty…</td><td>0.4</td><td>null</td><td>0.6</td></tr><tr><td>&quot;random_2_novel…</td><td>0.172136</td><td>0.27356</td><td>0.554303</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────────┬──────────┬──────────┬──────────┐\n",
       "│ name                    ┆ Positive ┆ Neutral  ┆ Negative │\n",
       "│ ---                     ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ str                     ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞═════════════════════════╪══════════╪══════════╪══════════╡\n",
       "│ editorial_picks_novelty ┆ 0.4      ┆ 0.2      ┆ 0.4      │\n",
       "│ popular_novelty         ┆ 0.2      ┆ null     ┆ 0.8      │\n",
       "│ random_novelty          ┆ 0.172136 ┆ 0.275046 ┆ 0.552817 │\n",
       "│ newest_novelty          ┆ 0.4      ┆ null     ┆ 0.6      │\n",
       "│ random_2_novelty        ┆ 0.172136 ┆ 0.27356  ┆ 0.554303 │\n",
       "└─────────────────────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMN = DEFAULT_SENTIMENT_LABEL_COL\n",
    "\n",
    "distribution_dict = {\n",
    "    f\"{list_name}_{novelty.name}\": distribution(\n",
    "        candidates,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=COLUMN,\n",
    "    )\n",
    "    for candidates, list_name in candidates_name_pairs\n",
    "}\n",
    "\n",
    "distribution_sentiment_dict = concat_distribution_dict(distribution_dict)\n",
    "pl.DataFrame(distribution_sentiment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution - Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 63)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>Underholdning</th><th>Film og tv</th><th>Transportmiddel</th><th>Bil</th><th>Økonomi</th><th>Mikro</th><th>Kriminalitet</th><th>Kendt</th><th>Personfarlig kriminalitet</th><th>Sport</th><th>Fodbold</th><th>Katastrofe</th><th>Større transportmiddel</th><th>Samfund</th><th>Større katastrofe</th><th>Begivenhed</th><th>Musik og lyd</th><th>Underholdningsbegivenhed</th><th>Mindre ulykke</th><th>Uddannelse</th><th>Ungdomsuddannelse</th><th>Politik</th><th>International politik</th><th>Sportsbegivenhed</th><th>National politik</th><th>Erhverv</th><th>Privat virksomhed</th><th>Ketcher- og batsport</th><th>Ansættelsesforhold</th><th>Bolig</th><th>Køb og salg</th><th>Motorsport</th><th>Makro</th><th>Livsstil</th><th>Videnskab</th><th>Naturvidenskab</th><th>Sundhed</th><th>Sygdom og behandling</th><th>Konflikt og krig</th><th>Væbnet konflikt</th><th>Familieliv</th><th>Udlejning</th><th>Håndbold</th><th>Dyr</th><th>Kultur</th><th>Mad og drikke</th><th>Offentlig instans</th><th>Bedrageri</th><th>Vejr</th><th>Bæredygtighed og klima</th><th>Kosmetisk behandling</th><th>Bandekriminalitet</th><th>Offentlig transport</th><th>Partnerskab</th><th>Teknologi</th><th>Kunstig intelligens og software</th><th>Værdier</th><th>Reality</th><th>Renovering og indretning</th><th>Forbrugerelektronik</th><th>Grundskole</th><th>Museum og seværdighed</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;editorial_pick…</td><td>0.066667</td><td>0.066667</td><td>0.066667</td><td>0.066667</td><td>0.133333</td><td>0.133333</td><td>0.133333</td><td>0.066667</td><td>0.133333</td><td>0.066667</td><td>0.066667</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;popular_novelt…</td><td>0.058824</td><td>null</td><td>0.117647</td><td>0.117647</td><td>null</td><td>null</td><td>0.058824</td><td>0.058824</td><td>0.058824</td><td>null</td><td>null</td><td>0.117647</td><td>0.117647</td><td>0.058824</td><td>0.058824</td><td>0.058824</td><td>0.058824</td><td>0.058824</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;random_novelty…</td><td>0.041881</td><td>0.011129</td><td>0.021944</td><td>0.009154</td><td>0.027335</td><td>0.007367</td><td>0.054577</td><td>0.104201</td><td>0.035266</td><td>0.067618</td><td>0.044796</td><td>0.02116</td><td>0.008056</td><td>0.016426</td><td>0.001411</td><td>0.044765</td><td>0.015956</td><td>0.016144</td><td>0.014451</td><td>0.006207</td><td>0.006207</td><td>0.046959</td><td>0.020063</td><td>0.025047</td><td>0.025266</td><td>0.066426</td><td>0.029122</td><td>0.00953</td><td>0.031599</td><td>0.015705</td><td>0.01279</td><td>0.003448</td><td>0.012351</td><td>0.025235</td><td>0.001411</td><td>0.001411</td><td>0.013574</td><td>0.011912</td><td>0.010282</td><td>0.003542</td><td>0.003542</td><td>0.001442</td><td>0.003229</td><td>0.001975</td><td>0.001944</td><td>0.004796</td><td>0.003574</td><td>0.003009</td><td>0.003511</td><td>0.003135</td><td>0.001693</td><td>0.004295</td><td>0.001442</td><td>0.003072</td><td>0.006364</td><td>0.00326</td><td>0.003229</td><td>0.001693</td><td>0.001473</td><td>0.001599</td><td>null</td><td>null</td></tr><tr><td>&quot;newest_novelty…</td><td>0.15</td><td>0.05</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.15</td><td>null</td><td>null</td><td>null</td><td>0.1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.05</td><td>null</td><td>0.1</td><td>0.05</td><td>null</td><td>0.05</td><td>null</td><td>null</td><td>0.05</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.05</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.05</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.05</td><td>null</td><td>null</td><td>0.05</td><td>0.05</td></tr><tr><td>&quot;random_2_novel…</td><td>0.041764</td><td>0.011231</td><td>0.0229</td><td>0.00951</td><td>0.026498</td><td>0.006163</td><td>0.053715</td><td>0.104114</td><td>0.034069</td><td>0.068763</td><td>0.044205</td><td>0.021367</td><td>0.009291</td><td>0.016299</td><td>0.001658</td><td>0.045081</td><td>0.015548</td><td>0.01583</td><td>0.015298</td><td>0.006601</td><td>0.006601</td><td>0.047302</td><td>0.020554</td><td>0.025872</td><td>0.02484</td><td>0.065947</td><td>0.029032</td><td>0.010762</td><td>0.032066</td><td>0.015799</td><td>0.01242</td><td>0.003598</td><td>0.012013</td><td>0.023964</td><td>0.001533</td><td>0.001533</td><td>0.012576</td><td>0.011168</td><td>0.010136</td><td>0.003473</td><td>0.003128</td><td>0.001721</td><td>0.003566</td><td>0.001283</td><td>0.00147</td><td>0.005005</td><td>0.003003</td><td>0.003629</td><td>0.002784</td><td>0.003254</td><td>0.001408</td><td>0.004317</td><td>0.00194</td><td>0.002972</td><td>0.007258</td><td>0.003441</td><td>0.003785</td><td>0.001595</td><td>0.001658</td><td>0.001689</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 63)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ name      ┆ Underhold ┆ Film og   ┆ Transport ┆ … ┆ Renoverin ┆ Forbruger ┆ Grundskol ┆ Museum   │\n",
       "│ ---       ┆ ning      ┆ tv        ┆ middel    ┆   ┆ g og indr ┆ elektroni ┆ e         ┆ og sevær │\n",
       "│ str       ┆ ---       ┆ ---       ┆ ---       ┆   ┆ etning    ┆ k         ┆ ---       ┆ dighed   │\n",
       "│           ┆ f64       ┆ f64       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ f64       ┆ ---      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ f64       ┆ f64       ┆           ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ editorial ┆ 0.066667  ┆ 0.066667  ┆ 0.066667  ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ _picks_no ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ velty     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ popular_n ┆ 0.058824  ┆ null      ┆ 0.117647  ┆ … ┆ null      ┆ null      ┆ null      ┆ null     │\n",
       "│ ovelty    ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ random_no ┆ 0.041881  ┆ 0.011129  ┆ 0.021944  ┆ … ┆ 0.001473  ┆ 0.001599  ┆ null      ┆ null     │\n",
       "│ velty     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ newest_no ┆ 0.15      ┆ 0.05      ┆ null      ┆ … ┆ null      ┆ null      ┆ 0.05      ┆ 0.05     │\n",
       "│ velty     ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ random_2_ ┆ 0.041764  ┆ 0.011231  ┆ 0.0229    ┆ … ┆ 0.001658  ┆ 0.001689  ┆ null      ┆ null     │\n",
       "│ novelty   ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMN = DEFAULT_TOPICS_COL\n",
    "\n",
    "distribution_dict = {\n",
    "    f\"{list_name}_{novelty.name}\": distribution(\n",
    "        candidates,\n",
    "        lookup_dict=articles_dict,\n",
    "        lookup_key=COLUMN,\n",
    "    )\n",
    "    for candidates, list_name in candidates_name_pairs\n",
    "}\n",
    "\n",
    "distribution_topics_dict = concat_distribution_dict(distribution_dict)\n",
    "pl.DataFrame(distribution_topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
