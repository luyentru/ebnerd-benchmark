{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello\n",
    "\n",
    "This notebook is an example of how to make a beyond-accuracy dataset, and how one could make baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEHAVIORS_TIMESTAMP_DICT = \"behaviors_timestamp_dict.json\"\n",
    "CANDIDATE_LIST = \"candidate_list.json\"\n",
    "CANDIDATE_DICT = \"candidate_dict.json\"\n",
    "USERS_DICT = \"users_dict.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebrec.utils._python import write_json_file, read_json_file\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "    DEFAULT_ARTICLE_MODIFIED_TIMESTAMP_COL,\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL,\n",
    "    DEFAULT_TOTAL_PAGEVIEWS_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_SENTIMENT_SCORE_COL,\n",
    "    DEFAULT_SENTIMENT_LABEL_COL,\n",
    "    DEFAULT_TOTAL_INVIEWS_COL,\n",
    "    DEFAULT_IS_SUBSCRIBER_COL,\n",
    "    DEFAULT_CATEGORY_STR_COL,\n",
    "    DEFAULT_IS_SSO_USER_COL,\n",
    "    DEFAULT_ARTICLE_ID_COL,\n",
    "    DEFAULT_POSTCODE_COL,\n",
    "    DEFAULT_TOPICS_COL,\n",
    "    DEFAULT_GENDER_COL,\n",
    "    DEFAULT_AGE_COL,\n",
    ")\n",
    "\n",
    "from ebrec.evaluation.beyond_accuracy import (\n",
    "    IntralistDiversity,\n",
    "    Distribution,\n",
    "    Serendipity,\n",
    "    Sentiment,\n",
    "    Coverage,\n",
    "    Novelty,\n",
    ")\n",
    "\n",
    "from ebrec.utils._articles import create_sort_based_prediction_score\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = \"large\"\n",
    "\n",
    "PATH = Path(f\"../downloads/{dataset_split}\")\n",
    "PATH_BEYOND_ACCURACY = PATH.joinpath(\"beyond_accuracy\")\n",
    "PATH_BEYOND_ACCURACY.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "df_beyond_accuarcy = pl.scan_parquet(PATH.joinpath(\"test\", \"behaviors.parquet\")).filter(pl.col(\"is_beyond_accuracy\"))\n",
    "df_behaviors = pl.scan_parquet(PATH.joinpath(\"test\", \"behaviors.parquet\")).filter(~pl.col(\"is_beyond_accuracy\"))\n",
    "df_articles = pl.scan_parquet(PATH.joinpath(\"articles.parquet\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make / Dump Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make candidate list for beyond-accuracy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the candidate list from the testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Candidate IDs: 250 (example: [9793163, 9793069, 9792076, 9792749, 9791280])\n",
      "Dump: ../downloads/large/beyond_accuracy/candidate_list.json\n"
     ]
    }
   ],
   "source": [
    "candidate_list = (\n",
    "    df_beyond_accuarcy.select(pl.col(DEFAULT_INVIEW_ARTICLES_COL).first())\n",
    "    .collect()\n",
    "    .to_series()\n",
    ")[0].to_list()\n",
    "write_json_file(candidate_list, PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST))\n",
    "\n",
    "print(f\"Number of Candidate IDs: {len(candidate_list)} (example: {candidate_list[:5]})\")\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "santity check - passed\n"
     ]
    }
   ],
   "source": [
    "load_candidate_list = read_json_file(PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST))\n",
    "if (\n",
    "    not (\n",
    "        df_beyond_accuarcy.select(DEFAULT_INVIEW_ARTICLES_COL).collect()\n",
    "        == candidate_list\n",
    "    )\n",
    "    .sum()[DEFAULT_INVIEW_ARTICLES_COL]\n",
    "    .to_list()[0]\n",
    "    == df_beyond_accuarcy.select(DEFAULT_INVIEW_ARTICLES_COL).collect().shape[0]\n",
    "):\n",
    "    raise ValueError(\"candidate_list is not identical in the testset\")\n",
    "\n",
    "if not (np.array(candidate_list) - np.array(load_candidate_list)).sum() == 0:\n",
    "    raise ValueError(\"candidate_list was not dump correctly\")\n",
    "\n",
    "print(\"santity check - passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User meta data: Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: ../downloads/large/beyond_accuracy/users_dict.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>is_subscriber</th><th>is_sso_user</th><th>postcode</th><th>gender</th><th>age</th></tr><tr><td>bool</td><td>bool</td><td>i8</td><td>i8</td><td>i8</td></tr></thead><tbody><tr><td>true</td><td>true</td><td>null</td><td>0</td><td>null</td></tr><tr><td>true</td><td>true</td><td>null</td><td>null</td><td>null</td></tr><tr><td>true</td><td>true</td><td>null</td><td>0</td><td>50</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 5)\n",
       "┌───────────────┬─────────────┬──────────┬────────┬──────┐\n",
       "│ is_subscriber ┆ is_sso_user ┆ postcode ┆ gender ┆ age  │\n",
       "│ ---           ┆ ---         ┆ ---      ┆ ---    ┆ ---  │\n",
       "│ bool          ┆ bool        ┆ i8       ┆ i8     ┆ i8   │\n",
       "╞═══════════════╪═════════════╪══════════╪════════╪══════╡\n",
       "│ true          ┆ true        ┆ null     ┆ 0      ┆ null │\n",
       "│ true          ┆ true        ┆ null     ┆ null   ┆ null │\n",
       "│ true          ┆ true        ┆ null     ┆ 0      ┆ 50   │\n",
       "└───────────────┴─────────────┴──────────┴────────┴──────┘"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_meta_columns = [\n",
    "    DEFAULT_IS_SUBSCRIBER_COL,\n",
    "    DEFAULT_IS_SSO_USER_COL,\n",
    "    DEFAULT_POSTCODE_COL,\n",
    "    DEFAULT_GENDER_COL,\n",
    "    DEFAULT_AGE_COL,\n",
    "]\n",
    "df_users = df_beyond_accuarcy.select(pl.col(user_meta_columns)).collect()\n",
    "\n",
    "users_dict = {col : df_users[col].to_list() for col in df_users.columns}\n",
    "write_json_file(users_dict, PATH_BEYOND_ACCURACY.joinpath(USERS_DICT))\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(USERS_DICT)}\")\n",
    "df_users.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp for Behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be used for making the AUC as function of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: ../downloads/large/beyond_accuracy/behaviors_timestamp_dict.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>impression_time</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;2023-06-05 15:…</td></tr><tr><td>&quot;2023-06-05 15:…</td></tr><tr><td>&quot;2023-06-05 15:…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 1)\n",
       "┌────────────────────────────┐\n",
       "│ impression_time            │\n",
       "│ ---                        │\n",
       "│ str                        │\n",
       "╞════════════════════════════╡\n",
       "│ 2023-06-05 15:02:49.000000 │\n",
       "│ 2023-06-05 15:03:56.000000 │\n",
       "│ 2023-06-05 15:25:53.000000 │\n",
       "└────────────────────────────┘"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_behaviors_timestamp = (\n",
    "    df_behaviors.select(\n",
    "        pl.col(DEFAULT_IMPRESSION_TIMESTAMP_COL).cast(pl.Utf8),\n",
    "    )\n",
    "    .collect()\n",
    ")\n",
    "behaviors_timestamp_dict = {\n",
    "    DEFAULT_IMPRESSION_TIMESTAMP_COL: df_behaviors_timestamp[\n",
    "        DEFAULT_IMPRESSION_TIMESTAMP_COL\n",
    "    ].to_list()\n",
    "}\n",
    "write_json_file(\n",
    "    behaviors_timestamp_dict, PATH_BEYOND_ACCURACY.joinpath(BEHAVIORS_TIMESTAMP_DICT)\n",
    ")\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(BEHAVIORS_TIMESTAMP_DICT)}\")\n",
    "df_behaviors_timestamp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Candidate lookup dict / Dump lookup dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Candidate articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make candidate lookup dictionary for beyond-accuracy:\n",
    "# =>\n",
    "df_candidate_articles = (\n",
    "    df_articles.filter(pl.col(DEFAULT_ARTICLE_ID_COL).is_in(candidate_list))\n",
    "    .with_columns(\n",
    "        pl.col(\n",
    "            DEFAULT_ARTICLE_MODIFIED_TIMESTAMP_COL,\n",
    "            DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL,\n",
    "        ).cast(pl.Utf8)\n",
    "    )\n",
    "    # Zeros might cause issues\n",
    "    .with_columns(\n",
    "        pl.col(DEFAULT_TOTAL_INVIEWS_COL, DEFAULT_TOTAL_PAGEVIEWS_COL).fill_null(1)\n",
    "    )\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add embeddings representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 25)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th><th>contrastive_vector</th><th>FacebookAI/xlm-roberta-base</th><th>google-bert/bert-base-multilingual-cased</th><th>document_vector</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>str</td><td>bool</td><td>str</td><td>str</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td><td>list[f32]</td><td>list[f32]</td><td>list[f32]</td><td>list[f32]</td></tr></thead><tbody><tr><td>9777912</td><td>&quot;Stort galleri:…</td><td>&quot;Den tyske topm…</td><td>&quot;2023-10-11 05:…</td><td>true</td><td>&quot;Heidi Klums la…</td><td>&quot;2023-06-01 11:…</td><td>[9777875, 9777930, … 9777889]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Bergisch Gladbach&quot;, &quot;Flavio Briatore&quot;, … &quot;Heidi Klums&quot;]</td><td>[&quot;LOC&quot;, &quot;PER&quot;, … &quot;PER&quot;]</td><td>[&quot;Kendt&quot;, &quot;Livsstil&quot;, &quot;Underholdning&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>793993</td><td>40407</td><td>1.742984e6</td><td>0.5703</td><td>&quot;Neutral&quot;</td><td>[-0.046561, -0.017556, … 0.003914]</td><td>[0.095054, 0.096886, … -0.013514]</td><td>[-0.097854, 0.062035, … -0.098488]</td><td>[0.071191, 0.016312, … 0.020225]</td></tr><tr><td>9780773</td><td>&quot;Afsløring: Hvi…</td><td>&quot;Hovsa:&quot;</td><td>&quot;2023-06-29 06:…</td><td>false</td><td>&quot;Ved du noget o…</td><td>&quot;2023-06-01 18:…</td><td>[9789766, 9791805]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Allan Melander&quot;, &quot;Christian Bartholdy&quot;, … &quot;Strandgade&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;, … &quot;LOC&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Bedrageri&quot;, … &quot;Økonomi&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>343369</td><td>63807</td><td>5.806831e6</td><td>0.9254</td><td>&quot;Negative&quot;</td><td>[-0.006871, 0.040639, … 0.142761]</td><td>[0.106638, 0.110743, … -0.012386]</td><td>[-0.083905, 0.007199, … 0.000927]</td><td>[0.000026, -0.042221, … 0.011401]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 25)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ contrasti ┆ FacebookA ┆ google-be ┆ document │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ ve_vector ┆ I/xlm-rob ┆ rt/bert-b ┆ _vector  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ erta-base ┆ ase-multi ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ str       ┆   ┆ list[f32] ┆ ---       ┆ lingu…    ┆ list[f32 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ list[f32] ┆ ---       ┆ ]        │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ list[f32] ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 9777912   ┆ Stort     ┆ Den tyske ┆ 2023-10-1 ┆ … ┆ [-0.04656 ┆ [0.095054 ┆ [-0.09785 ┆ [0.07119 │\n",
       "│           ┆ galleri:  ┆ topmodel, ┆ 1 05:20:0 ┆   ┆ 1, -0.017 ┆ ,         ┆ 4,        ┆ 1, 0.016 │\n",
       "│           ┆ Topmodel  ┆ tv-vært   ┆ 1.000000  ┆   ┆ 556, …    ┆ 0.096886, ┆ 0.062035, ┆ 312, …   │\n",
       "│           ┆ fylder 5… ┆ og p…     ┆           ┆   ┆ 0.00391…  ┆ … -0.0135 ┆ …         ┆ 0.020225 │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ 14…       ┆ -0.09848… ┆ ]        │\n",
       "│ 9780773   ┆ Afsløring ┆ Hovsa:    ┆ 2023-06-2 ┆ … ┆ [-0.00687 ┆ [0.106638 ┆ [-0.08390 ┆ [0.00002 │\n",
       "│           ┆ : Hvidvas ┆           ┆ 9 06:49:0 ┆   ┆ 1,        ┆ ,         ┆ 5,        ┆ 6, -0.04 │\n",
       "│           ┆ k-firma   ┆           ┆ 4.000000  ┆   ┆ 0.040639, ┆ 0.110743, ┆ 0.007199, ┆ 2221, …  │\n",
       "│           ┆ arbejd…   ┆           ┆           ┆   ┆ …         ┆ … -0.0123 ┆ …         ┆ 0.011401 │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 0.142761… ┆ 86…       ┆ 0.000927… ┆ …        │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# => Embeddings:\n",
    "BERT_VECTOR = \"bert_base_multilingual_cased\"\n",
    "CONTRASTIVE_VECTOR = \"contrastive_vector\"\n",
    "DOCUMENT_VECTOR = \"document_vector\"\n",
    "ROBERTA_VECTOR = \"xlm_roberta_base\"\n",
    "\n",
    "def load_join_embeddings(df:pl.DataFrame, emb_path:Path) -> pl.DataFrame:\n",
    "    emb_contrastive = (\n",
    "        pl.scan_parquet(\n",
    "            PATH.parent.joinpath(emb_path)\n",
    "        )\n",
    "        .filter(\n",
    "            pl.col(DEFAULT_ARTICLE_ID_COL).is_in(df.select(DEFAULT_ARTICLE_ID_COL))\n",
    "        ).collect()\n",
    "    )\n",
    "    return df.join(emb_contrastive, on=DEFAULT_ARTICLE_ID_COL, how = \"left\")\n",
    "\n",
    "df_candidate_articles = (\n",
    "    df_candidate_articles.pipe(\n",
    "        load_join_embeddings,\n",
    "        emb_path=f\"embeddings/Ekstra_Bladet_contrastive_vector/{CONTRASTIVE_VECTOR}.parquet\",\n",
    "    )\n",
    "    .pipe(\n",
    "        load_join_embeddings,\n",
    "        emb_path=f\"embeddings/FacebookAI_xlm_roberta_base/{ROBERTA_VECTOR}.parquet\",\n",
    "    )\n",
    "    .pipe(\n",
    "        load_join_embeddings,\n",
    "        emb_path=f\"embeddings/google_bert_base_multilingual_cased/{BERT_VECTOR}.parquet\"\n",
    "    )\n",
    "    .pipe(\n",
    "        load_join_embeddings,\n",
    "        emb_path=f\"embeddings/Ekstra_Bladet_word2vec/{DOCUMENT_VECTOR}.parquet\"\n",
    "    )\n",
    ")\n",
    "df_candidate_articles.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to lookup dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump: ../downloads/large/beyond_accuracy/candidate_dict.json\n"
     ]
    }
   ],
   "source": [
    "candidate_dict = {}\n",
    "for row in df_candidate_articles.iter_rows(named=True):\n",
    "    # Note, all keys in dictionaries are converted to strings, when serializing an object to JSON format.\n",
    "    candidate_dict[str(row[DEFAULT_ARTICLE_ID_COL])] = row\n",
    "# Write it:\n",
    "write_json_file(candidate_dict, PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_DICT))\n",
    "print(f\"Dump: {PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_DICT)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a couple *Baselines* based on the candidate-list:\n",
    "1. @EditorialPicks: We approximate this based on the number **inview** an articles have recived. Ekstra Bladet is front-page driven, meaning, if an article has a lot of inview-impression (seen) a lot, we believe it has been selected to be in a top priority from the editors. This is static (it does change for our *candidate_list*), i.e., the computation is done once.\n",
    "2. @Popular: We approximate this based on the number **clicks** an articles have recived. This is static (it does change for our *candidate_list*), i.e., the computation is done once.\n",
    "3. @Random: Simple baseline and important baseline. We simple pick a set of *top-n* articles from the *candidate-list* and run multiple times.\n",
    "4. @Dissimilarity / Similarity (will come later): Select top-n articles that are the most similar / dissimilar. \n",
    "5. @Newest: Simply pick the newest released articles. We do see newssite where the top banner is *Newest released*. We include it, but note this is very sensitive and might not be meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['article_id', 'title', 'subtitle', 'last_modified_time', 'premium', 'body', 'published_time', 'image_ids', 'article_type', 'url', 'ner_clusters', 'entity_groups', 'topics', 'category', 'subcategory', 'category_str', 'total_inviews', 'total_pageviews', 'total_read_time', 'sentiment_score', 'sentiment_label', 'contrastive_vector', 'FacebookAI/xlm-roberta-base', 'google-bert/bert-base-multilingual-cased', 'document_vector'])\n"
     ]
    }
   ],
   "source": [
    "behaviors_timestamp_dict = read_json_file(PATH_BEYOND_ACCURACY.joinpath(BEHAVIORS_TIMESTAMP_DICT))\n",
    "candidate_list = read_json_file(PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_LIST))\n",
    "candidate_dict = read_json_file(PATH_BEYOND_ACCURACY.joinpath(CANDIDATE_DICT))\n",
    "users_dict = read_json_file(PATH_BEYOND_ACCURACY.joinpath(USERS_DICT))\n",
    "\n",
    "# Only the once actually found in the dataset (for demo only 154 of 250 are represent)\n",
    "candidate_list = [str(id) for id in candidate_list if str(id) in list(candidate_dict)]\n",
    "\n",
    "print(candidate_dict[list(candidate_dict)[0]].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Ranked Candidate lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editorical Pick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬───────────────┬──────────────────┐\n",
      "│ article_id ┆ total_inviews ┆ prediction_score │\n",
      "│ ---        ┆ ---           ┆ ---              │\n",
      "│ i32        ┆ i32           ┆ f64              │\n",
      "╞════════════╪═══════════════╪══════════════════╡\n",
      "│ 9790335    ┆ 1698890       ┆ 1.0              │\n",
      "│ 9791587    ┆ 1369829       ┆ 0.5              │\n",
      "└────────────┴───────────────┴──────────────────┘\n",
      "[['9790335' '9791587']]\n"
     ]
    }
   ],
   "source": [
    "df_candidates_editorial_picks = create_sort_based_prediction_score(df_candidate_articles, column=DEFAULT_TOTAL_INVIEWS_COL, desc=True)\n",
    "candidates_editorial_picks = np.array([df_candidates_editorial_picks.select(DEFAULT_ARTICLE_ID_COL).cast(pl.Utf8).to_series()])\n",
    "# =>\n",
    "print(df_candidates_editorial_picks.head(2))\n",
    "print(candidates_editorial_picks[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬─────────────────┬──────────────────┐\n",
      "│ article_id ┆ total_pageviews ┆ prediction_score │\n",
      "│ ---        ┆ ---             ┆ ---              │\n",
      "│ i32        ┆ i32             ┆ f64              │\n",
      "╞════════════╪═════════════════╪══════════════════╡\n",
      "│ 9791428    ┆ 256541          ┆ 1.0              │\n",
      "│ 9792719    ┆ 209050          ┆ 0.5              │\n",
      "└────────────┴─────────────────┴──────────────────┘\n",
      "[['9791428' '9792719']]\n"
     ]
    }
   ],
   "source": [
    "df_candidates_popular = create_sort_based_prediction_score(df_candidate_articles, column=DEFAULT_TOTAL_PAGEVIEWS_COL, desc=True)\n",
    "candidates_popular = np.array([df_candidates_popular.select(DEFAULT_ARTICLE_ID_COL).cast(pl.Utf8).to_series()])\n",
    "# => \n",
    "print(df_candidates_popular.head(2))\n",
    "print(candidates_popular[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬────────────────────────────┬──────────────────┐\n",
      "│ article_id ┆ published_time             ┆ prediction_score │\n",
      "│ ---        ┆ ---                        ┆ ---              │\n",
      "│ i32        ┆ str                        ┆ f64              │\n",
      "╞════════════╪════════════════════════════╪══════════════════╡\n",
      "│ 9790515    ┆ 2023-06-01 07:02:14.000000 ┆ 1.0              │\n",
      "│ 9791205    ┆ 2023-06-01 07:06:57.000000 ┆ 0.5              │\n",
      "└────────────┴────────────────────────────┴──────────────────┘\n",
      "[['9790515' '9791205']]\n"
     ]
    }
   ],
   "source": [
    "df_candidates_newest = create_sort_based_prediction_score(df_candidate_articles, column=DEFAULT_ARTICLE_PUBLISHED_TIMESTAMP_COL, desc=False)\n",
    "candidates_newest = np.array([df_candidates_newest.select(DEFAULT_ARTICLE_ID_COL).cast(pl.Utf8).to_series()])\n",
    "# => \n",
    "print(df_candidates_newest.head(2))\n",
    "print(candidates_newest[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "┌────────────┬────────────────────────────┬──────────────────┐\n",
      "│ article_id ┆ published_time             ┆ prediction_score │\n",
      "│ ---        ┆ ---                        ┆ ---              │\n",
      "│ i32        ┆ str                        ┆ f64              │\n",
      "╞════════════╪════════════════════════════╪══════════════════╡\n",
      "│ 9790515    ┆ 2023-06-01 07:02:14.000000 ┆ 1.0              │\n",
      "│ 9791205    ┆ 2023-06-01 07:06:57.000000 ┆ 0.5              │\n",
      "└────────────┴────────────────────────────┴──────────────────┘\n",
      "[['9790515' '9791205']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "candidates_random = np.array([df_candidates_newest.select(DEFAULT_ARTICLE_ID_COL).cast(pl.Utf8).to_series()])\n",
    "# => \n",
    "print(df_candidates_newest.head(2))\n",
    "print(candidates_newest[:, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "instralist_diversity = IntralistDiversity()\n",
    "distribution = Distribution()\n",
    "serendipity = Serendipity()\n",
    "sentiment = Sentiment()\n",
    "coverage = Coverage()\n",
    "novelty = Novelty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select @n Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_ITER = 10_000\n",
    "TOP_N = 5\n",
    "\n",
    "n_candidates_random = [np.random.choice(list(candidate_dict), size=TOP_N, replace=False) for _ in range(RANDOM_ITER)]\n",
    "n_candidates_editorial_picks = candidates_editorial_picks[:, :TOP_N]\n",
    "n_candidates_popular = candidates_popular[:, :TOP_N]\n",
    "n_candidates_newest = candidates_newest[:, :TOP_N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instralist-Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>intralist_diversity_editorial_picks</th><th>intralist_diversity_popular</th><th>intralist_diversity_random</th><th>intralist_diversity_diversity_newest</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.790542</td><td>0.840236</td><td>0.730538</td><td>0.754899</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌────────────────────────┬────────────────────────┬────────────────────────┬───────────────────────┐\n",
       "│ intralist_diversity_ed ┆ intralist_diversity_po ┆ intralist_diversity_ra ┆ intralist_diversity_d │\n",
       "│ itorial_pi…            ┆ pular                  ┆ ndom                   ┆ iversity_ne…          │\n",
       "│ ---                    ┆ ---                    ┆ ---                    ┆ ---                   │\n",
       "│ f64                    ┆ f64                    ┆ f64                    ┆ f64                   │\n",
       "╞════════════════════════╪════════════════════════╪════════════════════════╪═══════════════════════╡\n",
       "│ 0.790542               ┆ 0.840236               ┆ 0.730538               ┆ 0.754899              │\n",
       "└────────────────────────┴────────────────────────┴────────────────────────┴───────────────────────┘"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instralist_diversity_dict = {\n",
    "    f\"{instralist_diversity.name}_editorial_picks\" : instralist_diversity(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=CONTRASTIVE_VECTOR)[0],\n",
    "    f\"{instralist_diversity.name}_popular\" : instralist_diversity(n_candidates_popular, lookup_dict=candidate_dict, lookup_key=CONTRASTIVE_VECTOR)[0],\n",
    "    f\"{instralist_diversity.name}_random\" : instralist_diversity(n_candidates_random, lookup_dict=candidate_dict, lookup_key=CONTRASTIVE_VECTOR)[0],\n",
    "    f\"{instralist_diversity.name}_diversity_newest\" : instralist_diversity(candidates_newest, lookup_dict=candidate_dict, lookup_key=CONTRASTIVE_VECTOR)[0],\n",
    "}\n",
    "pl.DataFrame(instralist_diversity_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The embedding representation\n",
    "This might be obvious, but the embedding representation used for computing a metric is very influential. Hence, baselines are important to determine high and low scores. Also, this is why these metrics can be very hard to interpret for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contrastive_vector: 0.7905415595169083\n",
      "document_vector: 0.1584846028291677\n",
      "FacebookAI/xlm-roberta-base: 0.0007398918387222619\n",
      "google-bert/bert-base-multilingual-cased: 0.028635621408856893\n"
     ]
    }
   ],
   "source": [
    "ROBERTA_EMB = \"FacebookAI/xlm-roberta-base\"\n",
    "BERT_EMB = \"google-bert/bert-base-multilingual-cased\"\n",
    "\n",
    "print(f\"{CONTRASTIVE_VECTOR}: {instralist_diversity(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=CONTRASTIVE_VECTOR)[0]}\")\n",
    "print(f\"{DOCUMENT_VECTOR}: {instralist_diversity(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=DOCUMENT_VECTOR)[0]}\")\n",
    "print(f\"{ROBERTA_EMB}: {instralist_diversity(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=ROBERTA_EMB)[0]}\")\n",
    "print(f\"{BERT_EMB}: {instralist_diversity(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=BERT_EMB)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sentiment_editorial_picks</th><th>sentiment_popular</th><th>sentiment_random</th><th>sentiment_diversity_newest</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0.7294</td><td>0.78342</td><td>0.82532</td><td>0.821488</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌───────────────────────────┬───────────────────┬──────────────────┬────────────────────────────┐\n",
       "│ sentiment_editorial_picks ┆ sentiment_popular ┆ sentiment_random ┆ sentiment_diversity_newest │\n",
       "│ ---                       ┆ ---               ┆ ---              ┆ ---                        │\n",
       "│ f64                       ┆ f64               ┆ f64              ┆ f64                        │\n",
       "╞═══════════════════════════╪═══════════════════╪══════════════════╪════════════════════════════╡\n",
       "│ 0.7294                    ┆ 0.78342           ┆ 0.82532          ┆ 0.821488                   │\n",
       "└───────────────────────────┴───────────────────┴──────────────────┴────────────────────────────┘"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_dict = {\n",
    "    f\"{sentiment.name}_editorial_picks\" : sentiment(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_SCORE_COL)[0],\n",
    "    f\"{sentiment.name}_popular\" : sentiment(n_candidates_popular, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_SCORE_COL)[0],\n",
    "    f\"{sentiment.name}_random\" : sentiment(n_candidates_random, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_SCORE_COL)[0],\n",
    "    f\"{sentiment.name}_diversity_newest\" : sentiment(candidates_newest, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_SCORE_COL)[0],\n",
    "}\n",
    "pl.DataFrame(sentiment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serendipity [MISSING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD USER HISTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Novelty [Novelty SCORE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>novelty_editorial_picks</th><th>novelty_popular</th><th>novelty_random</th><th>novelty_diversity_newest</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>-16.01345</td><td>-17.572331</td><td>-9.651651</td><td>-9.543215</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌─────────────────────────┬─────────────────┬────────────────┬──────────────────────────┐\n",
       "│ novelty_editorial_picks ┆ novelty_popular ┆ novelty_random ┆ novelty_diversity_newest │\n",
       "│ ---                     ┆ ---             ┆ ---            ┆ ---                      │\n",
       "│ f64                     ┆ f64             ┆ f64            ┆ f64                      │\n",
       "╞═════════════════════════╪═════════════════╪════════════════╪══════════════════════════╡\n",
       "│ -16.01345               ┆ -17.572331      ┆ -9.651651      ┆ -9.543215                │\n",
       "└─────────────────────────┴─────────────────┴────────────────┴──────────────────────────┘"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novelty_dict = {\n",
    "    f\"{novelty.name}_editorial_picks\" : novelty(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=DEFAULT_TOTAL_PAGEVIEWS_COL)[0],\n",
    "    f\"{novelty.name}_popular\" : novelty(n_candidates_popular, lookup_dict=candidate_dict, lookup_key=DEFAULT_TOTAL_PAGEVIEWS_COL)[0],\n",
    "    f\"{novelty.name}_random\" : novelty(n_candidates_random, lookup_dict=candidate_dict, lookup_key=DEFAULT_TOTAL_PAGEVIEWS_COL)[0],\n",
    "    f\"{novelty.name}_diversity_newest\" : novelty(candidates_newest, lookup_dict=candidate_dict, lookup_key=DEFAULT_TOTAL_PAGEVIEWS_COL)[0],\n",
    "}\n",
    "pl.DataFrame(novelty_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>coverage_editorial_picks</th><th>coverage_popular</th><th>coverage_random</th><th>coverage_newest</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>5.0</td><td>5.0</td><td>250.0</td><td>5.0</td></tr><tr><td>0.02</td><td>0.02</td><td>1.0</td><td>0.02</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 4)\n",
       "┌──────────────────────────┬──────────────────┬─────────────────┬─────────────────┐\n",
       "│ coverage_editorial_picks ┆ coverage_popular ┆ coverage_random ┆ coverage_newest │\n",
       "│ ---                      ┆ ---              ┆ ---             ┆ ---             │\n",
       "│ f64                      ┆ f64              ┆ f64             ┆ f64             │\n",
       "╞══════════════════════════╪══════════════════╪═════════════════╪═════════════════╡\n",
       "│ 5.0                      ┆ 5.0              ┆ 250.0           ┆ 5.0             │\n",
       "│ 0.02                     ┆ 0.02             ┆ 1.0             ┆ 0.02            │\n",
       "└──────────────────────────┴──────────────────┴─────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_dict = {\n",
    "    f\"{coverage.name}_editorial_picks\" : coverage(n_candidates_editorial_picks, candidate_list),\n",
    "    f\"{coverage.name}_popular\" : coverage(n_candidates_popular, candidate_list),\n",
    "    f\"{coverage.name}_random\" : coverage(n_candidates_random, candidate_list),\n",
    "    f\"{coverage.name}_newest\" : coverage(n_candidates_newest, candidate_list),\n",
    "}\n",
    "pl.DataFrame(coverage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transform_distribution(\n",
    "    R,\n",
    "    lookup_dict: dict,\n",
    "    lookup_key: str,\n",
    "    suffix: str,\n",
    "):\n",
    "    # =>\n",
    "    distribution = Distribution()\n",
    "    return {\n",
    "        **{\"name\": f\"{distribution.name}{suffix}\"},\n",
    "        **distribution(\n",
    "            R,\n",
    "            lookup_dict=lookup_dict,\n",
    "            lookup_key=lookup_key,\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution - Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>forbrug</th><th>nyheder</th><th>krimi</th><th>sport</th><th>penge</th><th>auto</th><th>underholdning</th><th>musik</th><th>nationen</th><th>incoming</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;distribution_e…</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;distribution_p…</td><td>null</td><td>0.2</td><td>0.2</td><td>0.4</td><td>0.2</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&quot;distribution_r…</td><td>0.01148</td><td>0.16282</td><td>0.09896</td><td>0.16754</td><td>0.03454</td><td>0.38024</td><td>0.08304</td><td>0.03522</td><td>0.02226</td><td>0.0039</td></tr><tr><td>&quot;distribution_n…</td><td>null</td><td>null</td><td>0.4</td><td>0.2</td><td>0.2</td><td>null</td><td>0.2</td><td>null</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 11)\n",
       "┌────────────────┬─────────┬─────────┬─────────┬───┬───────────────┬─────────┬──────────┬──────────┐\n",
       "│ name           ┆ forbrug ┆ nyheder ┆ krimi   ┆ … ┆ underholdning ┆ musik   ┆ nationen ┆ incoming │\n",
       "│ ---            ┆ ---     ┆ ---     ┆ ---     ┆   ┆ ---           ┆ ---     ┆ ---      ┆ ---      │\n",
       "│ str            ┆ f64     ┆ f64     ┆ f64     ┆   ┆ f64           ┆ f64     ┆ f64      ┆ f64      │\n",
       "╞════════════════╪═════════╪═════════╪═════════╪═══╪═══════════════╪═════════╪══════════╪══════════╡\n",
       "│ distribution_e ┆ 0.2     ┆ 0.2     ┆ 0.2     ┆ … ┆ null          ┆ null    ┆ null     ┆ null     │\n",
       "│ ditorial_picks ┆         ┆         ┆         ┆   ┆               ┆         ┆          ┆          │\n",
       "│ distribution_p ┆ null    ┆ 0.2     ┆ 0.2     ┆ … ┆ null          ┆ null    ┆ null     ┆ null     │\n",
       "│ opular         ┆         ┆         ┆         ┆   ┆               ┆         ┆          ┆          │\n",
       "│ distribution_r ┆ 0.01148 ┆ 0.16282 ┆ 0.09896 ┆ … ┆ 0.08304       ┆ 0.03522 ┆ 0.02226  ┆ 0.0039   │\n",
       "│ andom          ┆         ┆         ┆         ┆   ┆               ┆         ┆          ┆          │\n",
       "│ distribution_n ┆ null    ┆ null    ┆ 0.4     ┆ … ┆ 0.2           ┆ null    ┆ null     ┆ null     │\n",
       "│ ewest          ┆         ┆         ┆         ┆   ┆               ┆         ┆          ┆          │\n",
       "└────────────────┴─────────┴─────────┴─────────┴───┴───────────────┴─────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distribution_category = pl.concat([\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=DEFAULT_CATEGORY_STR_COL, suffix=\"_editorial_picks\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_popular, lookup_dict=candidate_dict, lookup_key=DEFAULT_CATEGORY_STR_COL, suffix=\"_popular\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_random, lookup_dict=candidate_dict, lookup_key=DEFAULT_CATEGORY_STR_COL, suffix=\"_random\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_newest, lookup_dict=candidate_dict, lookup_key=DEFAULT_CATEGORY_STR_COL, suffix=\"_newest\")),\n",
    "], how=\"diagonal\")\n",
    "# =>\n",
    "df_distribution_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution - Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>Negative</th><th>Positive</th><th>Neutral</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;distribution_e…</td><td>0.4</td><td>0.6</td><td>null</td></tr><tr><td>&quot;distribution_p…</td><td>0.2</td><td>0.4</td><td>0.4</td></tr><tr><td>&quot;distribution_r…</td><td>0.39534</td><td>0.3143</td><td>0.29036</td></tr><tr><td>&quot;distribution_n…</td><td>0.6</td><td>0.2</td><td>0.2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌──────────────────────────────┬──────────┬──────────┬─────────┐\n",
       "│ name                         ┆ Negative ┆ Positive ┆ Neutral │\n",
       "│ ---                          ┆ ---      ┆ ---      ┆ ---     │\n",
       "│ str                          ┆ f64      ┆ f64      ┆ f64     │\n",
       "╞══════════════════════════════╪══════════╪══════════╪═════════╡\n",
       "│ distribution_editorial_picks ┆ 0.4      ┆ 0.6      ┆ null    │\n",
       "│ distribution_popular         ┆ 0.2      ┆ 0.4      ┆ 0.4     │\n",
       "│ distribution_random          ┆ 0.39534  ┆ 0.3143   ┆ 0.29036 │\n",
       "│ distribution_newest          ┆ 0.6      ┆ 0.2      ┆ 0.2     │\n",
       "└──────────────────────────────┴──────────┴──────────┴─────────┘"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distribution_sentiment = pl.concat([\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_editorial_picks\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_popular, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_popular\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_random, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_random\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_newest, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_newest\")),\n",
    "], how=\"diagonal\")\n",
    "# =>\n",
    "df_distribution_sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution - Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (4, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>name</th><th>Negative</th><th>Positive</th><th>Neutral</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;distribution_e…</td><td>0.4</td><td>0.6</td><td>null</td></tr><tr><td>&quot;distribution_p…</td><td>0.2</td><td>0.4</td><td>0.4</td></tr><tr><td>&quot;distribution_r…</td><td>0.39534</td><td>0.3143</td><td>0.29036</td></tr><tr><td>&quot;distribution_n…</td><td>0.6</td><td>0.2</td><td>0.2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (4, 4)\n",
       "┌──────────────────────────────┬──────────┬──────────┬─────────┐\n",
       "│ name                         ┆ Negative ┆ Positive ┆ Neutral │\n",
       "│ ---                          ┆ ---      ┆ ---      ┆ ---     │\n",
       "│ str                          ┆ f64      ┆ f64      ┆ f64     │\n",
       "╞══════════════════════════════╪══════════╪══════════╪═════════╡\n",
       "│ distribution_editorial_picks ┆ 0.4      ┆ 0.6      ┆ null    │\n",
       "│ distribution_popular         ┆ 0.2      ┆ 0.4      ┆ 0.4     │\n",
       "│ distribution_random          ┆ 0.39534  ┆ 0.3143   ┆ 0.29036 │\n",
       "│ distribution_newest          ┆ 0.6      ┆ 0.2      ┆ 0.2     │\n",
       "└──────────────────────────────┴──────────┴──────────┴─────────┘"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_distribution_topics = pl.concat([\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_editorial_picks, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_editorial_picks\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_popular, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_popular\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_random, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_random\")),\n",
    "    pl.DataFrame(compute_transform_distribution(n_candidates_newest, lookup_dict=candidate_dict, lookup_key=DEFAULT_SENTIMENT_LABEL_COL, suffix=\"_newest\")),\n",
    "], how=\"diagonal\")\n",
    "# =>\n",
    "df_distribution_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
